{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f05aca-9e64-46ad-af1d-4baa9e2fa9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 11:12:43.610949: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-06 11:12:43.640668: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-06 11:12:43.640695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-06 11:12:43.642101: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-06 11:12:43.647324: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cdist, cosine\n",
    "from sklearn.preprocessing import normalize\n",
    "import tensorflow as tf\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.cbook as cbook\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset, num2date, date2num\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import cmocean as cmocn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "955fc5ae-3535-41ac-be64-a55b2f3cc6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('../rainFlagRemovedBuoyDataBadQualityRemovedMatchup.nc')\n",
    "df = ds.to_dataframe()\n",
    "df_orig = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ec57e1-b791-4b2f-98e7-0118f4a53ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Speed Difference (QuikSCAT - TAO)'] = df['Wind Speed (QuikSCAT)'] - df['Wind Speed (TAO)']\n",
    "\n",
    "df['Wind Direction (TAO)'] = (-(df['Wind Direction (TAO)'] - 90.0) + 360)%360\n",
    "df['Wind Direction (QuikSCAT)'] = (-(df['Wind Direction (QuikSCAT)'] - 90.0) + 360)%360\n",
    "df['mean WDIR 30min'] = (-(df['mean WDIR 30min'] - 90.0) + 360)%360\n",
    "df['mean WDIR 60min'] = (-(df['mean WDIR 60min'] - 90.0) + 360)%360\n",
    "df['mean WDIR 120min'] = (-(df['mean WDIR 120min'] - 90.0) + 360)%360\n",
    "\n",
    "df['Direction Difference (QuikSCAT - TAO)'] = ((df['Wind Direction (QuikSCAT)'] - df['Wind Direction (TAO)'])+360)%360\n",
    "dirDiff = np.array(df['Direction Difference (QuikSCAT - TAO)'])\n",
    "dirDiff[dirDiff > 180] -= 360\n",
    "df['Direction Difference (QuikSCAT - TAO)'] = dirDiff\n",
    "\n",
    "df['Speed Difference (QuikSCAT - TAO 30 min mean)'] = df['Wind Speed (QuikSCAT)'] - df['mean WSPD 30min']\n",
    "df['Direction Difference (QuikSCAT - TAO 30 min mean)'] = ((df['Wind Direction (QuikSCAT)'] - df['mean WDIR 30min'])+360)%360\n",
    "dirDiff = np.array(df['Direction Difference (QuikSCAT - TAO 30 min mean)'])\n",
    "dirDiff[dirDiff > 180] -= 360\n",
    "df['Direction Difference (QuikSCAT - TAO 30 min mean)'] = dirDiff\n",
    "\n",
    "df['Speed Difference (QuikSCAT - TAO 1 hr mean)'] = df['Wind Speed (QuikSCAT)'] - df['mean WSPD 60min']\n",
    "df['Direction Difference (QuikSCAT - TAO 1 hr mean)'] = ((df['Wind Direction (QuikSCAT)'] - df['mean WDIR 60min'])+360)%360\n",
    "dirDiff = np.array(df['Direction Difference (QuikSCAT - TAO 1 hr mean)'])\n",
    "dirDiff[dirDiff > 180] -= 360\n",
    "df['Direction Difference (QuikSCAT - TAO 1 hr mean)'] = dirDiff\n",
    "\n",
    "df['Speed Difference (QuikSCAT - TAO 2 hr mean)'] = df['Wind Speed (QuikSCAT)'] - df['mean WSPD 120min']\n",
    "df['Direction Difference (QuikSCAT - TAO 2 hr mean)'] = ((df['Wind Direction (QuikSCAT)'] - df['mean WDIR 120min'])+360)%360\n",
    "dirDiff = np.array(df['Direction Difference (QuikSCAT - TAO 2 hr mean)'])\n",
    "dirDiff[dirDiff > 180] -= 360\n",
    "df['Direction Difference (QuikSCAT - TAO 2 hr mean)'] = dirDiff\n",
    "\n",
    "\n",
    "df['Zonal Neutral Wind Speed at 10m (TAO)'] = df['Neutral Wind Speed at 10m (TAO)']*np.cos(np.deg2rad(df['Wind Direction (TAO)']))\n",
    "df['Meridional Neutral Wind Speed at 10m (TAO)'] = df['Neutral Wind Speed at 10m (TAO)']*np.sin(np.deg2rad(df['Wind Direction (TAO)']))\n",
    "\n",
    "df['Zonal Neutral Wind Speed at 10m (QuikSCAT)'] = df['Wind Speed (QuikSCAT)']*np.cos(np.deg2rad(df['Wind Direction (QuikSCAT)']))\n",
    "df['Meridional Neutral Wind Speed at 10m (QuikSCAT)'] = df['Wind Speed (QuikSCAT)']*np.sin(np.deg2rad(df['Wind Direction (QuikSCAT)']))\n",
    "\n",
    "df['Zonal Wind Speed Difference (QuikSCAT - TAO)'] = df['Zonal Neutral Wind Speed at 10m (QuikSCAT)'] - df['Zonal Neutral Wind Speed at 10m (TAO)']\n",
    "df['Meridional Wind Speed Difference (QuikSCAT - TAO)'] = df['Meridional Neutral Wind Speed at 10m (QuikSCAT)'] - df['Meridional Neutral Wind Speed at 10m (TAO)']\n",
    "\n",
    "df['cos(Direction Difference (QuikSCAT - TAO))'] = np.cos(np.deg2rad(df['Direction Difference (QuikSCAT - TAO)']))\n",
    "df['sin(Direction Difference (QuikSCAT - TAO))'] = np.sin(np.deg2rad(df['Direction Difference (QuikSCAT - TAO)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d724b1c1-54be-470e-b8ce-1b391f838237",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = abs(df['Speed Difference (QuikSCAT - TAO)'])\n",
    "x = x - np.mean(x)/np.std(x)\n",
    "\n",
    "y = abs(df['Speed Difference (QuikSCAT - TAO)'])\n",
    "y = y - np.mean(y)/np.std(y)\n",
    "\n",
    "df['distance from origin'] = np.sqrt(x**2 + y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b55e26-f49c-4a0f-88dc-3b2a68c6d858",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:46\u001b[0;36m\u001b[0m\n\u001b[0;31m    delayed(silhouette_score_sample)(i, X, labels) for i in range(len(X))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "selectX = ['Speed Difference (QuikSCAT - TAO)',\n",
    "           'cos(Direction Difference (QuikSCAT - TAO))',\n",
    "           'sin(Direction Difference (QuikSCAT - TAO))'] #,\n",
    "           'distance from origin']\n",
    "\n",
    "X = df[selectX]\n",
    "normX = (X - X.mean(axis=0))/ X.std(axis=0)\n",
    "#normX = normalize(X.to_numpy())\n",
    "\n",
    "# Function to compute silhouette score for one sample\n",
    "def silhouette_score_sample(i, X, labels, metric='euclidean'):\n",
    "    mask = np.ones(len(X), dtype=bool)\n",
    "    mask[i] = False\n",
    "    current_label = labels[i]\n",
    "    \n",
    "    # Calculate a(i)\n",
    "    a_i = np.mean(pairwise_distances([X[i]], X[labels == current_label], metric=metric)[0])\n",
    "    \n",
    "    # Calculate b(i)\n",
    "    b_i = np.inf\n",
    "    for label in np.unique(labels):\n",
    "        if label == current_label:\n",
    "            continue\n",
    "        b_i = min(b_i, np.mean(pairwise_distances([X[i]], X[labels == label], metric=metric)[0]))\n",
    "    \n",
    "    return (b_i - a_i) / max(a_i, b_i)\n",
    "    \n",
    "def getScore(n_cluster, X):\n",
    "    # Fit KMeans\n",
    "    kmeans = KMeans(n_clusters=n_cluster, random_state=42, n_init='auto').fit(X)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # # Fit Cosine Similarity\n",
    "    # data = X\n",
    "    # labels, centroids = kmeans_cosine(data, n_cluster)\n",
    "\n",
    "    # gmm = GaussianMixture(n_components=n_cluster, random_state=0)\n",
    "    # gmm.fit(X)\n",
    "    \n",
    "    # Predict the cluster for each data point\n",
    "    # labels = gmm.predict(X)\n",
    "    \n",
    "    # Calculate silhouette scores in parallel\n",
    "    n_jobs = -1  # Use all available cores\n",
    "    silhouette_scores = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(silhouette_score_sample)(i, X, labels) for i in range(len(X))\n",
    "    )  \n",
    "    # Calculate the average silhouette score\n",
    "    average_silhouette_score = np.mean(silhouette_scores)\n",
    "\n",
    "    return average_silhouette_score\n",
    "\n",
    "### Function to calculate cosine similarity\n",
    "def kmeans_cosine(X, n_clusters, max_iter=300, tol=1e-4):\n",
    "    # Normalize the data to make it suitable for cosine similarity\n",
    "    X_normalized = normalize(X)\n",
    "\n",
    "    # Randomly initialize the centroids\n",
    "    centroids = X_normalized[np.random.choice(X_normalized.shape[0], n_clusters, replace=False)]\n",
    "    #centroids = X[np.random.choice(X.shape[0], n_clusters, replace=False)]\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # Compute cosine distances between points and centroids\n",
    "        distances = cdist(X_normalized, centroids, metric='cosine')\n",
    "        #distances = cdist(X, centroids, metric='cosine')\n",
    "\n",
    "        # Assign clusters based on the closest centroids\n",
    "        clusters = np.argmin(distances, axis=1)\n",
    "\n",
    "        # Calculate new centroids\n",
    "        new_centroids = np.array([X_normalized[clusters == j].mean(axis=0) for j in range(n_clusters)])\n",
    "        #new_centroids = np.array([X[clusters == j].mean(axis=0) for j in range(n_clusters)])\n",
    "\n",
    "        # # Normalize new centroids\n",
    "        new_centroids = normalize(new_centroids)\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.allclose(centroids, new_centroids, atol=tol):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    return clusters, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c4050-34e0-4b1c-969c-4830cfe95d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = np.arange(2,10)\n",
    "silhouette_scores = []\n",
    "for n_cluster in range_n_clusters:\n",
    "    print(f'cluster : {n_cluster}')\n",
    "    silhouette_scores.append(getScore(n_cluster, normX.to_numpy()))\n",
    "\n",
    "silhouette_scores = np.array(silhouette_scores)\n",
    "index = np.argmax(silhouette_scores)\n",
    "best_n_clusters = range_n_clusters[index]\n",
    "best_score = silhouette_scores[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a443d-4b1f-4fca-8a06-933024f0f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range_n_clusters, silhouette_scores, marker='o')\n",
    "plt.title('Silhouette Score vs. Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.xticks(range_n_clusters)\n",
    "plt.grid(True)\n",
    "#plt.show()\n",
    "\n",
    "print(f'The optimal number of clusters is: {best_n_clusters} with a silhouette score of {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79372d-6408-444c-a9aa-fcfda9db5ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
